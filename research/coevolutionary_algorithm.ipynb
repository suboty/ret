{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae8875d2",
   "metadata": {},
   "source": [
    "# Coevolutionary algorithm\n",
    "with **GEP** and **Differential Evolution**\n",
    "\n",
    "The basic idea of a coevolutionary algorithm is as follows: several populations evolve simultaneously, each of which optimizes a given function and has its own optimization strategy. At the same time, the populations \"fight\" for a resource, which is redistributed in favor of the more effective of them during the operation of the algorithm.\n",
    "\n",
    "## Params of run\n",
    "- **Shared resource $N_s$**. The resource $N_s$ is the number of calculations of the objective function - the product of the population size and the number of iterations. Initially, the resource is assumed to be common and is equally divided between each population.\n",
    "- **Length of the adaptation interval $L_i$**. Setting the adaptation interval value during a certain number of steps (the so-called adaptation interval) each algorithm works separately. The adaptation interval value is determined and set by the researcher. Naturally, its value should not be small (the algorithms will not have time to show themselves) and large (there will be little time for adaptation)\n",
    "- **Amount of penalty for loss $P$**. The penalty is a certain percentage of the population size of the individual algorithm by which we will reduce the population size of the losing algorithms. Naturally, its value should not be too small (the algorithms will not feel the changes) or large (the search procedure for an algorithm with a small population size becomes meaningless).\n",
    "- **Size of the \"social\" card $C_s$**. \"Social card\" is a certain percentage of the population size of an individual algorithm, which is the minimum guaranteed population size. That is, we can reduce the losing population only until it reaches the minimum guaranteed size - \"social card\" (the necessity of this limitation has been proven in practice).\n",
    "\n",
    "## Evaluation of algorithms\n",
    "Since the coevolutionary algorithm is based on competing strategies of algorithms, a fitness function must be introduced for subpopulations. With the help of this function, the best population is determined and given more opportunities for reproduction.\n",
    "\n",
    "$\\Large q_i=\\sum_{k=0}^{L_i-1}\\frac{L_i-k}{k+1} \\cdot b_i(k)$\n",
    "\n",
    "where $k=0$ means the current situation, $k=1$ means previous situation, etc; $i$ means index of population; $b_i(k)=1$ if the $i$-th population at time $k$ contains the best (among all populations) individual.\n",
    "\n",
    "In the future, the obtained assessments of individual algorithms included in the coevolution are the main criterion for assessing the performance of algorithms and are used in the process of resource redistribution.\n",
    "\n",
    "## Efficiency of the coevolutionary algorithm\n",
    "The following indicators were used as comparison criteria: reliability $R$ and speed $V$. Reliability $R$ is the number (in percentage) of successful launches of the algorithm out of the total number of launches. Speed $V$ is estimated by the generation number in which the algorithm finds a solution with a given accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8801101",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf6359",
   "metadata": {},
   "source": [
    "### Init params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared resource\n",
    "SHARED_RESOURCE = 10000\n",
    "\n",
    "# length of the adaptation interval\n",
    "ADAPTATION_LENGTH = 25\n",
    "\n",
    "# amount of penalty for loss\n",
    "PENALTY = 0.05 # means 15% of population\n",
    "\n",
    "# size of population\n",
    "POPULATION_SIZE = 100\n",
    "\n",
    "# size of the \"social\" card\n",
    "SOCIAL_SIZE = 0.1 * POPULATION_SIZE # means 10% of population\n",
    "\n",
    "# set the seed\n",
    "SEED = 321\n",
    "\n",
    "# storage for input regexes params\n",
    "PARAMS = {}\n",
    "\n",
    "# storages for test dataset\n",
    "X, Y = [], []\n",
    "\n",
    "# number of iterations of performance metric\n",
    "N_ITER = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36d0760",
   "metadata": {},
   "source": [
    "### Prepare Coevolutionary Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f344e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "class CoevolutionaryManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        verbose: bool = False,\n",
    "    ):\n",
    "        self.shared_resources = SHARED_RESOURCE\n",
    "        self.adaptive_length = ADAPTATION_LENGTH\n",
    "        self.penalty = PENALTY\n",
    "        self.social_size = int(SOCIAL_SIZE)\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.algorithm_dict = {}\n",
    "        self.current_winner = None\n",
    "    \n",
    "    def register_algorithm(self, algorithm_name):\n",
    "        self.algorithm_dict[algorithm_name] = {\n",
    "            'individuals': [],\n",
    "            'population_number': 0,\n",
    "            'status': 'stop',\n",
    "            'score': 0,\n",
    "            'population_size': POPULATION_SIZE,\n",
    "            'validation_func': lambda _: True\n",
    "        }\n",
    "        \n",
    "    def add_individual(\n",
    "        self, \n",
    "        algorithm_name,\n",
    "        individual_str: str,\n",
    "        individual_metric: float\n",
    "    ):\n",
    "        self.algorithm_dict[algorithm_name]['individuals'].append(\n",
    "            (individual_str, individual_metric)\n",
    "        )\n",
    "        \n",
    "    def run_population(self, algorithm_name):\n",
    "        self.algorithm_dict[algorithm_name]['status'] = 'run'\n",
    "        self.algorithm_dict[algorithm_name]['population_number'] += 1\n",
    "        \n",
    "    def set_validation_function(self, algorithm_name, validation_func):\n",
    "        self.algorithm_dict[algorithm_name]['validation_func'] = validation_func\n",
    "        \n",
    "    def get_population_score(self, algorithm_name):\n",
    "        ### set the winner\n",
    "        return 1\n",
    "        \n",
    "    def stop_population(self, algorithm_name):\n",
    "        self.algorithm_dict[algorithm_name]['status'] = 'stop'\n",
    "        self.algorithm_dict[algorithm_name]['score'] = self.get_population_score(algorithm_name)\n",
    "        \n",
    "    def is_adaptive_population(self, algorithm_name):\n",
    "        return not self.algorithm_dict[algorithm_name]['population_number'] >= self.adaptive_length\n",
    "    \n",
    "    def get_resource(self):\n",
    "        if self.shared_resources:\n",
    "            self.shared_resources -= 1\n",
    "            if self.shared_resources % 1000 == 0:\n",
    "                print(f'--- Remaining resource: {self.shared_resources}')\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def get_population(self, population, algorithm_name):\n",
    "        if self.current_winner == algorithm_name:\n",
    "            new_population = []\n",
    "            for el in population:\n",
    "                if self.algorithm_dict[algorithm_name].get('validation_func')(el):\n",
    "                    new_population.append(el)\n",
    "        else:\n",
    "            new_population = []\n",
    "            population_length = len(population)\n",
    "            current_length = self.algorithm_dict[algorithm_name]['population_size'] * (1 - self.penalty)\n",
    "            current_length = int(current_length)\n",
    "            if current_length < self.social_size:\n",
    "                current_length = self.social_size\n",
    "            self.algorithm_dict[algorithm_name]['population_size'] = current_length\n",
    "            print(f'--- Current length of population: <{current_length}>')\n",
    "            for i, el in enumerate(population):\n",
    "                if len(new_population) == current_length:\n",
    "                    el = self.algorithm_dict[algorithm_name]['validation_func'](el)\n",
    "                new_population.append(el)\n",
    "        return new_population\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '''\n",
    "        1) <register_algorithm> // register algorithm\n",
    "            for each population:\n",
    "            2) <is_adaptive_population> // check nessary to run coevolutionary\n",
    "            3) <run_population> // send signal about population starting\n",
    "            if coevolutionary start:\n",
    "                4) <get_population> // filter population after previous population\n",
    "                    for each individual:\n",
    "                    5) <get_resource> // get resource for evaluate individual\n",
    "                        if resource is available:\n",
    "                            6) <add_individual> // register individual and his metric\n",
    "                7) <stop_population> // send signal about population stop\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523df85f",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c64d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "    @staticmethod\n",
    "    def get_match_accuracy(regex, phrase, result):\n",
    "        try:\n",
    "            reg_result = regex.match(phrase).group()\n",
    "            if reg_result == result:\n",
    "                return 1\n",
    "            return 0\n",
    "        except AttributeError:\n",
    "            return 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_performance_metric(regex, n_iter, test_strings):\n",
    "        t0 = time.time() * 1000\n",
    "        for _ in range(n_iter):\n",
    "            for test_string in test_strings:\n",
    "                _ = regex.match(test_string)\n",
    "        return ((time.time() * 1000 - t0) / n_iter) / len(test_strings)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942ce873",
   "metadata": {},
   "source": [
    "### Expression Tree to Regular Expression Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c667852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETtoRegexTranslator:\n",
    "    @staticmethod\n",
    "    def lexical_analyzer(string):\n",
    "        sep_symbols = ['(', ')', ',']\n",
    "        tokens = []\n",
    "        _current_token = ''\n",
    "        for symbol in string:\n",
    "            if symbol in sep_symbols:\n",
    "                if _current_token != '':\n",
    "                    tokens.append(_current_token)\n",
    "                tokens.append(symbol)\n",
    "                _current_token = ''\n",
    "            else:\n",
    "                _current_token += symbol\n",
    "        return tokens\n",
    "\n",
    "    @staticmethod\n",
    "    def generator(tokens, current_state=None):\n",
    "        global PARAMS\n",
    "        result = []\n",
    "        repeat = False\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token in TERMINALS:\n",
    "                # work with special terminals\n",
    "                if token == 'escape':\n",
    "                    result.append('\\\\')\n",
    "                elif token == 'any':\n",
    "                    result.append('.')\n",
    "                elif token == 'range':\n",
    "                    result.append(f'[{random.choice(PARAMS[\"range\"])}]')\n",
    "                else:\n",
    "                    result.append(token)\n",
    "            # add arguments\n",
    "            elif token == ',' and current_state == 'alt':\n",
    "                result.append('|')\n",
    "            elif token == ')' and repeat is True and current_state is None:\n",
    "                result.append(f'{\"{\"}{random.choice(PARAMS[\"repeat\"])}{\"}\"}')\n",
    "                repeat = False\n",
    "            elif token == '(' and current_state in ['group', 'alt']:\n",
    "                result.append(token)\n",
    "            elif token == ')':\n",
    "                current_state = None\n",
    "                result.append(')')\n",
    "            # check functions\n",
    "            elif token == 'group':\n",
    "                current_state = 'group'\n",
    "            elif token == 'repeat':\n",
    "                repeat = True\n",
    "            elif token == 'alt':\n",
    "                current_state = 'alt'\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def regex_compile(individual):\n",
    "        individual = re.sub(\n",
    "            r'\\s', \n",
    "            '', \n",
    "            str(individual)\n",
    "        )\n",
    "        tokens = ETtoRegexTranslator.lexical_analyzer(individual)\n",
    "        regex = ''.join(\n",
    "            ETtoRegexTranslator.generator(tokens)\n",
    "        ) + ')'\n",
    "        try:\n",
    "            return re.compile(regex), None\n",
    "        except Exception as e:\n",
    "            return None, f'error: {e}, string: {regex}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346e0858",
   "metadata": {},
   "source": [
    "### Incidence List to Regular Expression Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e690be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class NodesTypes(Enum):\n",
    "    params = -1\n",
    "    seq = 0\n",
    "    atom = 1\n",
    "    any = 2\n",
    "    repeat = 3\n",
    "    alt = 4\n",
    "    altgroup = 5\n",
    "    group = 6\n",
    "    range = 7\n",
    "    escape = 8\n",
    "\n",
    "class Nodes:\n",
    "    nodes_types = {}\n",
    "    max_id = 0\n",
    "\n",
    "    def __init__(self):\n",
    "        for node_type in NodesTypes.__members__:\n",
    "            value = NodesTypes.__members__.get(node_type).value\n",
    "            self.nodes_types[value] = node_type\n",
    "            self.max_id = value\n",
    "\n",
    "class ILtoRegexTranslator:\n",
    "    def __init__(self, incidence_list, nodes, params):\n",
    "        self.params = params\n",
    "        self.incidence_list = incidence_list\n",
    "        self.nodes = nodes\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_incidence_list(incidence_list):\n",
    "        previous_incidence = incidence_list[0]\n",
    "        new_incidence_list = [previous_incidence[0], previous_incidence[1]]\n",
    "\n",
    "        for incidence in incidence_list[1:]:\n",
    "            if incidence[0] == incidence[1] == 0:\n",
    "                new_incidence_list.append(-1)\n",
    "                continue\n",
    "            if previous_incidence[1] == incidence[0]:\n",
    "                new_incidence_list.append(incidence[1])\n",
    "                previous_incidence = incidence\n",
    "                continue\n",
    "            else:\n",
    "                new_incidence_list.append(incidence[0])\n",
    "                new_incidence_list.append(incidence[1])\n",
    "                previous_incidence = incidence\n",
    "\n",
    "        return new_incidence_list\n",
    "    \n",
    "    def get_regex(self, incidence_list):\n",
    "\n",
    "        regex = ''\n",
    "\n",
    "        is_alt = False\n",
    "        is_group = False\n",
    "        is_repeat = False\n",
    "\n",
    "        for incidence in incidence_list:\n",
    "            if incidence[0] == 0 and is_group:\n",
    "                regex += ')'\n",
    "            if incidence[0] == 3:\n",
    "                continue\n",
    "            match incidence[1]:\n",
    "                case 0:\n",
    "                    if incidence[0] == 0:\n",
    "                        continue\n",
    "                case 2:\n",
    "                    regex += '.'\n",
    "                case 3:\n",
    "                    if not is_repeat:\n",
    "                        is_repeat = True\n",
    "                    continue\n",
    "                case 5:\n",
    "                    if is_alt:\n",
    "                        regex += '|'\n",
    "                        is_alt = False\n",
    "                    else:\n",
    "                        is_alt = True\n",
    "                case 6:\n",
    "                    regex += '('\n",
    "                    is_group = True\n",
    "                case 7:\n",
    "                    _params = self.params.get('range')[0]\n",
    "                    regex += f'[{_params}]'\n",
    "                case 8:\n",
    "                    regex += '\\\\'\n",
    "                case _:\n",
    "                    if incidence[0] in [1, 8]:\n",
    "                        regex += self.nodes[incidence[1]]\n",
    "            if is_repeat:\n",
    "                _params = self.params.get('repeat')[0]\n",
    "                regex += f'{_params}'\n",
    "                is_repeat = False\n",
    "        return regex\n",
    "    \n",
    "    def regex_compile(self, individual):\n",
    "        try:\n",
    "            return re.compile(self.get_regex(individual)), None\n",
    "        except Exception as e:\n",
    "            return None, e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a789c2b0",
   "metadata": {},
   "source": [
    "### GEP class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1556679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deap\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "\n",
    "def _validate_basic_toolbox(tb):\n",
    "    assert hasattr(tb, 'select'), \"The toolbox must have a 'select' operator.\"\n",
    "    # whether the ops in .pbs are all registered\n",
    "    for op in tb.pbs:\n",
    "        assert op.startswith('mut') or op.startswith('cx'), \\\n",
    "        \"Operators must start with 'mut' or 'cx' except selection.\"\n",
    "        assert hasattr(tb, op), \"Probability for a operator called '{}' \\\n",
    "        is specified, but this operator is not \" \\\n",
    "                                \"registered in the toolbox.\".format(op)\n",
    "    # whether all the mut_ and cx_ operators have their probabilities assigned in .pbs\n",
    "    for op in [attr for attr in dir(tb) if attr.startswith('mut') or attr.startswith('cx')]:\n",
    "        if op not in tb.pbs:\n",
    "            warnings.warn('{0} is registered, \\\n",
    "            but its probability is NOT assigned in Toolbox.pbs. '\n",
    "                          'By default, \\\n",
    "                          the probability is ZERO and the operator {0} will NOT be applied.'.format(op),\n",
    "                          category=UserWarning)\n",
    "\n",
    "\n",
    "def _apply_modification(population, operator, pb):\n",
    "    for i in range(len(population)):\n",
    "        if random.random() < pb:\n",
    "            population[i], = operator(population[i])\n",
    "            del population[i].fitness.values\n",
    "    return population\n",
    "\n",
    "\n",
    "def _apply_crossover(population, operator, pb):\n",
    "    for i in range(1, len(population), 2):\n",
    "        if random.random() < pb:\n",
    "            population[i - 1], population[i] = operator(population[i - 1], population[i])\n",
    "            del population[i - 1].fitness.values\n",
    "            del population[i].fitness.values\n",
    "    return population\n",
    "\n",
    "\n",
    "def gep_simple(population, toolbox, n_generations=100, n_elites=1,\n",
    "               stats=None, hall_of_fame=None, verbose=__debug__):\n",
    "    \n",
    "    def validate_ind(ind):\n",
    "        try:\n",
    "            ind.fitness.valid = True\n",
    "        except:\n",
    "            pass\n",
    "        return ind\n",
    "    \n",
    "    ## for coevolutionary (step 1)\n",
    "    ce_manager.register_algorithm('gep')\n",
    "    ce_manager.set_validation_function(\n",
    "        algorithm_name='gep',\n",
    "        validation_func=validate_ind\n",
    "    )\n",
    "    ##\n",
    "    \n",
    "    _validate_basic_toolbox(toolbox)\n",
    "    logbook = deap.tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "    \n",
    "    ## for coevolutionary (step 2)\n",
    "    is_adaptive_population = True\n",
    "    ##\n",
    "\n",
    "    for gen in range(n_generations + 1):\n",
    "        \n",
    "        ## for coevolutionary (step 2)\n",
    "        is_adaptive_population = ce_manager.is_adaptive_population('gep')\n",
    "        ##\n",
    "        \n",
    "        ## for coevolutionary (step 3)\n",
    "        ce_manager.run_population('gep')\n",
    "        ##\n",
    "        \n",
    "        ## for coevolutionary (step 4)\n",
    "        if not is_adaptive_population:\n",
    "            invalid_individuals = ce_manager.get_population(\n",
    "                population=population,\n",
    "                algorithm_name='gep'\n",
    "            )\n",
    "            invalid_individuals = [ind for ind in invalid_individuals if not ind.fitness.valid]\n",
    "        else:\n",
    "            invalid_individuals = [ind for ind in population if not ind.fitness.valid]\n",
    "        ##       \n",
    "        \n",
    "        print(f'--- Size of population: <{len(invalid_individuals)}>')\n",
    "        \n",
    "        ind_errors = 0\n",
    "        ind_calculates = 0\n",
    "        is_end = False\n",
    "        for ind in invalid_individuals:\n",
    "            ind.fitness.values = toolbox.evaluate(ind)\n",
    "            ## for coevolutionary (step 5)\n",
    "            if ce_manager.get_resource():\n",
    "                try:\n",
    "                    ## for coevolutionary (step 6)\n",
    "                    ce_manager.add_individual(\n",
    "                        algorithm_name='gep',\n",
    "                        individual_str=ind,\n",
    "                        individual_metric=ind.fitness.values\n",
    "                    )\n",
    "                    ind_calculates += 1\n",
    "                except Exception as e:\n",
    "                    ind_errors += 1\n",
    "            else:\n",
    "                is_end = True\n",
    "                break\n",
    "            ##\n",
    "        \n",
    "        if is_end:\n",
    "            break\n",
    "        \n",
    "        if ind_errors:\n",
    "            print(f'Errors percent while fitness calculations: '\n",
    "                  f'{round(ind_errors/(ind_errors+ind_calculates),3)*100}%')\n",
    "\n",
    "        # record statistics and log\n",
    "        if hall_of_fame is not None:\n",
    "            hall_of_fame.update(population)\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_individuals), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "        if gen == n_generations:\n",
    "            break\n",
    "\n",
    "        # selection with elitism\n",
    "        elites = deap.tools.selBest(population, k=n_elites)\n",
    "        offspring = toolbox.select(population, len(population) - n_elites)\n",
    "\n",
    "        # replication\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "\n",
    "        # mutation\n",
    "        for op in toolbox.pbs:\n",
    "            if op.startswith('mut'):\n",
    "                offspring = _apply_modification(offspring, getattr(toolbox, op), toolbox.pbs[op])\n",
    "\n",
    "        # crossover\n",
    "        for op in toolbox.pbs:\n",
    "            if op.startswith('cx'):\n",
    "                offspring = _apply_crossover(offspring, getattr(toolbox, op), toolbox.pbs[op])\n",
    "\n",
    "        # replace the current population with the offsprings\n",
    "        population = elites + offspring\n",
    "        \n",
    "        ## for coevolutionary (step 7)\n",
    "        ce_manager.stop_population('gep')\n",
    "        ##\n",
    "        \n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135022ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from typing import List, Dict, Callable\n",
    "\n",
    "import exrex\n",
    "import geppy\n",
    "import numpy as np\n",
    "from deap import creator, base, tools\n",
    "\n",
    "\n",
    "def regex_process(string, regex):\n",
    "    re_comp = re.compile(regex)\n",
    "    try:\n",
    "        return re_comp.match(string).group()\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "\n",
    "class GEPAlgorithm:\n",
    "    \n",
    "    _statistics_dict = {\n",
    "        \"avg\": np.mean,\n",
    "        \"std\": np.std,\n",
    "        \"min\": np.min,\n",
    "        \"max\": np.max\n",
    "    }\n",
    "    \n",
    "    _seed = SEED\n",
    "    _verbose = True\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        head_n: int,\n",
    "        genes_n: int,\n",
    "        terminals: List,\n",
    "        functions: Dict,\n",
    "        evaluate_function: Callable,\n",
    "        population_size: int,\n",
    "        population_number: int,\n",
    "        n_elites: int,\n",
    "    ):\n",
    "        # init entities for algorithm\n",
    "        self.terminals = terminals\n",
    "        self.functions = functions\n",
    "        \n",
    "        # init GEP variables\n",
    "        self.head_n = head_n\n",
    "        self.genes_n = genes_n\n",
    "        \n",
    "        # test strings for check accuracy\n",
    "        self.test_strings = []\n",
    "        \n",
    "        # X and Y for test dataset\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        \n",
    "        # set evaluate function\n",
    "        self.evaluate_function = evaluate_function\n",
    "        \n",
    "        # set the evolution params\n",
    "        self.population_size = population_size\n",
    "        self.population_number = population_number\n",
    "        self.n_elites = n_elites\n",
    "             \n",
    "    @staticmethod\n",
    "    def get_test_strings(\n",
    "        input_regex: str,\n",
    "        n_fuzzy_strings: int,\n",
    "    ):\n",
    "        return list(\n",
    "            exrex.generate(\n",
    "                input_regex, \n",
    "                limit=n_fuzzy_strings)\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_training_set(\n",
    "        test_strings: List,\n",
    "        original_regex: str,\n",
    "        process_func: Callable\n",
    "    ):\n",
    "        Y = []\n",
    "        X = []\n",
    "        for string in test_strings:\n",
    "            X.append(string)\n",
    "            Y.append(\n",
    "                process_func(\n",
    "                    string=string, \n",
    "                    regex=original_regex\n",
    "                )\n",
    "            )\n",
    "        return X, Y\n",
    "    \n",
    "    def create_primitives_set(self):\n",
    "        # terminals\n",
    "        pset = geppy.PrimitiveSet('Main', input_names=self.terminals)\n",
    "\n",
    "        # functions\n",
    "        for function in self.functions.keys():\n",
    "            pset.add_function(function, self.functions.get(function))\n",
    "        return pset\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_individual():\n",
    "        # to minimize the objective (fitness)\n",
    "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1,))\n",
    "        creator.create(\"Individual\", geppy.Chromosome, fitness=creator.FitnessMin)\n",
    "        return creator\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_popiulation(\n",
    "        pset,\n",
    "        creator,\n",
    "        head_length: int = 5,\n",
    "        genes_number_in_chromosome: int = 2,\n",
    "    ):\n",
    "        print('--- Set the formula for individual: '\n",
    "              f'head: <{head_length}> and '\n",
    "              f'gene in chromosome: <{genes_number_in_chromosome}>')\n",
    "        toolbox = geppy.Toolbox()\n",
    "        toolbox.register('gene_gen', geppy.Gene, pset=pset, head_length=head_length)\n",
    "        toolbox.register(\n",
    "            'individual', \n",
    "            creator.Individual, \n",
    "            gene_gen=toolbox.gene_gen, \n",
    "            n_genes=genes_number_in_chromosome,\n",
    "            linker=group\n",
    "        )\n",
    "        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "        toolbox.register('compile', geppy.compile_, pset=pset)\n",
    "        return toolbox\n",
    "    \n",
    "    def set_evalute_function(self, toolbox):\n",
    "        toolbox.register('evaluate', self.evaluate_function)\n",
    "        return toolbox\n",
    "        \n",
    "    def set_genetic_operators(self, toolbox, pset):\n",
    "        toolbox.register('select', tools.selRoulette)\n",
    "        ## general mutations whose aliases start with 'mut'\n",
    "        # We can specify the probability for an operator with the .pbs property\n",
    "        toolbox.register(\n",
    "            'mut_uniform', \n",
    "            geppy.mutate_uniform, \n",
    "            pset=pset, \n",
    "            ind_pb=2 / (2 * self.head_n + 1)\n",
    "        )\n",
    "        toolbox.pbs['mut_uniform'] = 0.3\n",
    "        # Alternatively, assign the probability along with registration using the pb keyword argument.\n",
    "        toolbox.register('mut_invert', geppy.invert, pb=0.1)\n",
    "        toolbox.register('mut_is_ts', geppy.is_transpose, pb=0.1)\n",
    "        toolbox.register('mut_ris_ts', geppy.ris_transpose, pb=0.1)\n",
    "        toolbox.register('mut_gene_ts', geppy.gene_transpose, pb=0.4)\n",
    "\n",
    "        ## general crossover whose aliases start with 'cx'\n",
    "        toolbox.register('cx_1p', geppy.crossover_one_point, pb=0.1)\n",
    "        toolbox.pbs['cx_1p'] = 0.4   # just show that the probability can be overwritten\n",
    "        toolbox.register('cx_2p', geppy.crossover_two_point, pb=0.2)\n",
    "        toolbox.register('cx_gene', geppy.crossover_gene, pb=0.1)\n",
    "        \n",
    "        return toolbox\n",
    "        \n",
    "    def set_statistic(self):\n",
    "        stats = tools.Statistics(key=lambda ind: ind.fitness.values[0])\n",
    "        for statistic_name in self._statistics_dict.keys():\n",
    "            stats.register(\n",
    "                statistic_name, \n",
    "                self._statistics_dict[statistic_name]\n",
    "            )\n",
    "        return stats\n",
    "    \n",
    "    def launch_evolution(\n",
    "        self,\n",
    "        toolbox,\n",
    "        stats\n",
    "    ):\n",
    "        random.seed(self._seed)\n",
    "\n",
    "        pop = toolbox.population(\n",
    "            n=self.population_size\n",
    "        )\n",
    "        # only record the best individual ever found in all generations\n",
    "        hof = tools.HallOfFame(1)\n",
    "\n",
    "        # start evolution\n",
    "        pop, log = gep_simple(\n",
    "            pop, \n",
    "            toolbox,\n",
    "            n_generations=self.population_number,\n",
    "            n_elites=self.n_elites,\n",
    "            stats=stats,\n",
    "            hall_of_fame=hof, \n",
    "            verbose=self._verbose\n",
    "        )\n",
    "\n",
    "        best = hof[0]\n",
    "        return best\n",
    "    \n",
    "    def __call__(\n",
    "        self, \n",
    "        input_regex: str,\n",
    "        n_fuzzy_strings: int = 5,\n",
    "    ):\n",
    "        print('GEP algorithm starts...')\n",
    "        print(f'--- Get regex: <{input_regex}>')\n",
    "        self.test_strings = self.get_test_strings(\n",
    "            input_regex=input_regex,\n",
    "            n_fuzzy_strings=n_fuzzy_strings\n",
    "        )\n",
    "        \n",
    "        print(f'--- Get test strings: <{len(self.test_strings)}>')\n",
    "        \n",
    "        self.X, self.Y = self.create_training_set(\n",
    "            test_strings=self.test_strings,\n",
    "            original_regex=input_regex,\n",
    "            process_func=regex_process,\n",
    "        )\n",
    "        \n",
    "        global X, Y\n",
    "        X = self.X\n",
    "        Y = self.Y\n",
    "        \n",
    "        pset = self.create_primitives_set()\n",
    "        \n",
    "        creator = self.create_individual()\n",
    "        \n",
    "        toolbox = self.create_popiulation(\n",
    "            pset=pset,\n",
    "            creator=creator,\n",
    "            head_length=self.head_n,\n",
    "            genes_number_in_chromosome=self.genes_n,\n",
    "        )\n",
    "        \n",
    "        toolbox = self.set_evalute_function(toolbox)\n",
    "        \n",
    "        toolbox = self.set_genetic_operators(\n",
    "            toolbox=toolbox, \n",
    "            pset=pset,\n",
    "        )\n",
    "        \n",
    "        stats = self.set_statistic()\n",
    "        \n",
    "        return self.launch_evolution(\n",
    "            toolbox=toolbox,\n",
    "            stats=stats,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63274407",
   "metadata": {},
   "source": [
    "#### Prepare terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19886fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "from geppy.core.symbol import _is_nonkeyword_identifier\n",
    "\n",
    "def get_all_unicode_letters(start_code, stop_code):\n",
    "    start_idx, stop_idx = [int(code, 16) for code in (start_code, stop_code)]\n",
    "    characters = []\n",
    "    for unicode_idx in range(start_idx, stop_idx + 1):\n",
    "        characters.append(chr(unicode_idx))\n",
    "    return characters\n",
    "\n",
    "TERMINALS = []\n",
    "\n",
    "# Latin upper\n",
    "TERMINALS += get_all_unicode_letters('0041', '005A')\n",
    "\n",
    "# Latin lower\n",
    "TERMINALS += get_all_unicode_letters('0061', '007A')\n",
    "\n",
    "# digits\n",
    "TERMINALS += get_all_unicode_letters('0030', '0039')\n",
    "\n",
    "# check ability to get __name__\n",
    "correct_terminals = []\n",
    "\n",
    "for x in TERMINALS:\n",
    "    try:\n",
    "        assert _is_nonkeyword_identifier(x)\n",
    "        correct_terminals.append(x)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "TERMINALS = correct_terminals\n",
    "\n",
    "# range group and escape in this work will be terminals\n",
    "TERMINALS += ['range', 'any', 'escape']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49541d8",
   "metadata": {},
   "source": [
    "#### Prepare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a10ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy functions for naming\n",
    "def alt(*args):\n",
    "    return args\n",
    "    \n",
    "def group(*args):\n",
    "    return args\n",
    "\n",
    "def repeat(*args):\n",
    "    return args\n",
    "\n",
    "# Key - function object\n",
    "# Value - arity of function\n",
    "FUNCTIONS = {\n",
    "    alt: 2,\n",
    "    group: 10,\n",
    "    repeat: 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0959a38a",
   "metadata": {},
   "source": [
    "#### Prepare evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eaf18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gep_evaluate(individual):\n",
    "    global X, Y\n",
    "    regex = ETtoRegexTranslator.regex_compile(individual)[0]\n",
    "    if not regex:\n",
    "        return 1_000,\n",
    "    \n",
    "    # count accuracy metric\n",
    "    accuracy = []\n",
    "    for x, y in zip(X, Y):\n",
    "        accuracy.append(\n",
    "            Metrics.get_match_accuracy(\n",
    "                regex=regex, \n",
    "                phrase=x, \n",
    "                result=y\n",
    "            )\n",
    "        )\n",
    "    try:\n",
    "        accuracy = sum(accuracy)/len(accuracy)\n",
    "        res_metric = float(\n",
    "            Metrics.get_performance_metric(\n",
    "                regex=regex,\n",
    "                n_iter=N_ITER,\n",
    "                test_strings=X\n",
    "        )) / accuracy\n",
    "    except ZeroDivisionError:\n",
    "        res_metric = 1_000\n",
    "\n",
    "    return res_metric,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be850baf",
   "metadata": {},
   "source": [
    "#### prepare visualization of best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f2997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "rename_labels = {\n",
    "    'group': 'group', \n",
    "    'alt': 'alt', \n",
    "    'repeat': 'repeat', \n",
    "    'escape': 'escape', \n",
    "    '_range': 'range'\n",
    "}\n",
    "\n",
    "def visualize(ind):\n",
    "    geppy.export_expression_tree(ind, rename_labels, 'data/coevolutionary_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8910a1d3",
   "metadata": {},
   "source": [
    "### DE class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ee04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import array\n",
    "import random\n",
    "from typing import List, Dict, Callable\n",
    "\n",
    "import exrex\n",
    "import numpy as np\n",
    "from deap import creator, base, tools\n",
    "\n",
    "\n",
    "def regex_process(string, regex):\n",
    "    re_comp = re.compile(regex)\n",
    "    try:\n",
    "        return re_comp.match(string).group()\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "\n",
    "class DEAlgorithm:\n",
    "    \n",
    "    _statistics_dict = {\n",
    "        \"avg\": np.mean,\n",
    "        \"std\": np.std,\n",
    "        \"min\": np.min,\n",
    "        \"max\": np.max\n",
    "    }\n",
    "    \n",
    "    _de_dict = {\n",
    "        'cr': 0.6,\n",
    "        'f': 0.4,\n",
    "        'mu': 300,\n",
    "    }\n",
    "    \n",
    "    _verbose = True\n",
    "    _seed = SEED\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        bounds,\n",
    "        ndim,\n",
    "        evaluate_function: Callable,\n",
    "        population_size: int,\n",
    "        population_number: int,\n",
    "    ):\n",
    "        # de params\n",
    "        self.bounds = bounds\n",
    "        self.ndim = ndim\n",
    "        \n",
    "        # evolution params\n",
    "        self.population_size = population_size\n",
    "        self.population_number = population_number\n",
    "        \n",
    "        # test strings for check accuracy\n",
    "        self.test_strings = []\n",
    "        \n",
    "        # X and Y for test dataset\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        \n",
    "        # evaluate function\n",
    "        self.evaluate_function = evaluate_function\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_test_strings(\n",
    "        input_regex: str,\n",
    "        n_fuzzy_strings: int,\n",
    "    ):\n",
    "        return list(\n",
    "            exrex.generate(\n",
    "                input_regex, \n",
    "                limit=n_fuzzy_strings)\n",
    "        )\n",
    "        \n",
    "    @staticmethod\n",
    "    def create_training_set(\n",
    "        test_strings: List,\n",
    "        original_regex: str,\n",
    "        process_func: Callable\n",
    "    ):\n",
    "        Y = []\n",
    "        X = []\n",
    "        for string in test_strings:\n",
    "            X.append(string)\n",
    "            Y.append(\n",
    "                process_func(\n",
    "                    string=string, \n",
    "                    regex=original_regex\n",
    "                )\n",
    "            )\n",
    "        return X, Y\n",
    "    \n",
    "    def set_genetic_operators(self):\n",
    "        \n",
    "        toolbox = base.Toolbox()\n",
    "        toolbox.register(\"attr_float\", random.uniform, -3, 3)\n",
    "        toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, self.ndim)\n",
    "        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "        toolbox.register(\"select\", tools.selRandom, k=3)\n",
    "        \n",
    "        return toolbox\n",
    "        \n",
    "    @staticmethod\n",
    "    def create_individual():\n",
    "        # to minimize the objective (fitness)\n",
    "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "        creator.create(\"Individual\", array.array, typecode='d', fitness=creator.FitnessMin)\n",
    "        return creator\n",
    "    \n",
    "    def set_evalute_function(self, toolbox):\n",
    "        toolbox.register('evaluate', self.evaluate_function)\n",
    "        return toolbox\n",
    "    \n",
    "    def set_statistic(self):\n",
    "        stats = tools.Statistics(key=lambda ind: ind.fitness.values[0])\n",
    "        for statistic_name in self._statistics_dict.keys():\n",
    "            stats.register(\n",
    "                statistic_name, \n",
    "                self._statistics_dict[statistic_name]\n",
    "            )\n",
    "        return stats\n",
    "    \n",
    "    def create_popiulation(self, toolbox):\n",
    "        pop = toolbox.population(n=self._de_dict['mu']);\n",
    "        return pop\n",
    "    \n",
    "    def launch_evolution(\n",
    "        self,\n",
    "        toolbox,\n",
    "        stats,\n",
    "        pop\n",
    "    ):\n",
    "        random.seed(self._seed)\n",
    "\n",
    "        logbook = tools.Logbook()\n",
    "        logbook.header = \"gen\", \"evals\", \"std\", \"min\", \"avg\", \"max\"\n",
    "\n",
    "        # Evaluate the individuals\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, pop)\n",
    "        for ind, fit in zip(pop, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "            \n",
    "        hof = tools.HallOfFame(1)\n",
    "\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=0, evals=len(pop), **record)\n",
    "        print(logbook.stream)\n",
    "\n",
    "        for g in range(1, self.population_number):\n",
    "            for k, agent in enumerate(pop):\n",
    "                a,b,c = toolbox.select(pop)\n",
    "                y = toolbox.clone(agent)\n",
    "                index = random.randrange(self.ndim)\n",
    "                for i, value in enumerate(agent):\n",
    "                    if i == index or random.random() < self._de_dict['cr']:\n",
    "                        y[i] = a[i] + self._de_dict['f']*(b[i]-c[i])\n",
    "                y.fitness.values = toolbox.evaluate(y)\n",
    "                if y.fitness > agent.fitness:\n",
    "                    pop[k] = y\n",
    "            hof.update(pop)\n",
    "            record = stats.compile(pop)\n",
    "            logbook.record(gen=g, evals=len(pop), **record)\n",
    "            print(logbook.stream)\n",
    "\n",
    "        return hof[0]\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        input_regex: str,\n",
    "        n_fuzzy_strings: int = 5,\n",
    "    ):\n",
    "        print('#de# DE algorithm starts...')\n",
    "        print(f'#de# Get regex: <{input_regex}>')\n",
    "        self.test_strings = self.get_test_strings(\n",
    "            input_regex=input_regex,\n",
    "            n_fuzzy_strings=n_fuzzy_strings\n",
    "        )\n",
    "        \n",
    "        print(f'#de# Get test strings: <{len(self.test_strings)}>')\n",
    "        \n",
    "        self.X, self.Y = self.create_training_set(\n",
    "            test_strings=self.test_strings,\n",
    "            original_regex=input_regex,\n",
    "            process_func=regex_process,\n",
    "        )\n",
    "        \n",
    "        global X, Y\n",
    "        X = self.X\n",
    "        Y = self.Y\n",
    "        \n",
    "        creator = self.create_individual()\n",
    "        \n",
    "        toolbox = self.set_genetic_operators()\n",
    "        \n",
    "        pop = self.create_popiulation(toolbox)\n",
    "        \n",
    "        toolbox = self.set_evalute_function(toolbox)\n",
    "        \n",
    "        stats = self.set_statistic()\n",
    "        \n",
    "        return self.launch_evolution(\n",
    "            toolbox=toolbox,\n",
    "            stats=stats,\n",
    "            pop=pop,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88d516",
   "metadata": {},
   "source": [
    "#### Prepare evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c708e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "_translator = None\n",
    "\n",
    "\n",
    "def de_evaluate(individual):\n",
    "    \n",
    "    individual = np.array(\n",
    "        [abs(x) for x in individual.tolist()]\n",
    "    ).round().reshape((15 * 1, 2))\n",
    "    \n",
    "    global X, Y\n",
    "    \n",
    "    res = _translator.regex_compile(individual)\n",
    "    regex = res[0]\n",
    "    if not regex:\n",
    "        return 1_000,\n",
    "    \n",
    "    # count accuracy metric\n",
    "    accuracy = []\n",
    "    for x, y in zip(X, Y):\n",
    "        accuracy.append(\n",
    "            Metrics.get_match_accuracy(\n",
    "                regex=regex, \n",
    "                phrase=x, \n",
    "                result=y\n",
    "            )\n",
    "        )\n",
    "    try:\n",
    "        accuracy = sum(accuracy)/len(accuracy)\n",
    "        res_metric = float(\n",
    "            Metrics.get_performance_metric(\n",
    "                regex=regex,\n",
    "                n_iter=N_ITER,\n",
    "                test_strings=X\n",
    "        )) / accuracy\n",
    "    except ZeroDivisionError:\n",
    "        res_metric = 1_000\n",
    "\n",
    "    return res_metric,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e15ec",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffbc0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_globals():\n",
    "    global PARAMS, X, Y\n",
    "    X, Y = [], []\n",
    "    PARAMS = {}  \n",
    "    \n",
    "def set_globals():\n",
    "    global PARAMS, NODES, _translator\n",
    "    PARAMS = {\n",
    "        'range': ['0-9'],\n",
    "        'repeat': ['0,1']\n",
    "    }\n",
    "    \n",
    "    NODES = {\n",
    "        # functions (except any)\n",
    "        -1: 'params', \n",
    "        0: 'seq', \n",
    "        1: 'atom', \n",
    "        2: 'any', \n",
    "        3: 'repeat', \n",
    "        4: 'alt', \n",
    "        5: 'altgroup', \n",
    "        6: 'group', \n",
    "        7: 'range', \n",
    "        8: 'escape', \n",
    "        \n",
    "        # terminals (get by input regex)\n",
    "        9: 'a', \n",
    "        10: 'b', \n",
    "        11: 'c', \n",
    "        12: '['\n",
    "    }\n",
    "\n",
    "    _translator = ILtoRegexTranslator(\n",
    "        incidence_list = [(0, 4), (4, 5), (5, 1), (1, 9), (5, 3), (3, 1), (1, 10), (5, 1), (1, 11), (5, 2), (4, 5), (5, 7), (5, 8), (8, 12)],\n",
    "        nodes = NODES,\n",
    "        params = PARAMS\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b46c965",
   "metadata": {},
   "source": [
    "#### GEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de3e496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_globals()\n",
    "ce_manager = CoevolutionaryManager()\n",
    "\n",
    "gep = GEPAlgorithm(\n",
    "    terminals=TERMINALS,\n",
    "    functions=FUNCTIONS,\n",
    "    head_n=5,\n",
    "    genes_n=2,\n",
    "    evaluate_function=gep_evaluate,\n",
    "    population_size=POPULATION_SIZE,\n",
    "    population_number=1_000, # stub value due to limited resources\n",
    "    n_elites=2\n",
    ")\n",
    "\n",
    "best = gep(\n",
    "    input_regex='ab?c.|[0-9]\\['\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c18854",
   "metadata": {},
   "source": [
    "#### see the evaluate metric for best by GEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51095ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETtoRegexTranslator.regex_compile(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gep_evaluate(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ef458c",
   "metadata": {},
   "source": [
    "#### see the strucutre of best by GEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7c7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(best)\n",
    "Image(filename='data/coevolutionary_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad725dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d917a6",
   "metadata": {},
   "source": [
    "#### DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f4e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_globals()\n",
    "# ce_manager = CoevolutionaryManager()\n",
    "\n",
    "de = DEAlgorithm(\n",
    "    bounds=[0, 11],\n",
    "    ndim=15 * 2,\n",
    "    evaluate_function=de_evaluate,\n",
    "    population_size=POPULATION_SIZE,\n",
    "    population_number=10, # stub value due to limited resources\n",
    ")\n",
    "\n",
    "best = de(\n",
    "    input_regex='ab?c.|[0-9]\\['\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b3f99",
   "metadata": {},
   "source": [
    "#### see the evaluate metric for best by DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2779f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "de_evaluate(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f944b3e",
   "metadata": {},
   "source": [
    "#### see the strucutre of best by DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfbc58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = np.array(\n",
    "        [abs(x) for x in best.tolist()]\n",
    "    ).round().reshape((15 * 1, 2))\n",
    "\n",
    "_translator.regex_compile(best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
