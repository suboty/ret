{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic regression on regular expressions\n",
    "\n",
    "by **G**ene **E**xpression **P**rogramming (GEP)\n",
    "\n",
    "Matherials from [geppy documentation](https://geppy.readthedocs.io/en/latest/intro_GEP.html)\n",
    "\n",
    "## Useful theory\n",
    "\n",
    "### Symbolic regression\n",
    "```\n",
    "Symbolic regression is a type of regression analysis that searches the space of mathematical expressions to find the model that best fits a given dataset, both in terms of accuracy and simplicity.\n",
    "```\n",
    "\n",
    "### Gene expression programming (GEP)\n",
    "```\n",
    "Gene expression programming (GEP) belongs to the family of evolutionary algorithms and is closely related to genetic algorithms and genetic programming (GP). Like GP, GEP is a special field of evolutionary computation that aims at building programs automatically to solve problems independently of their domain, i.e., the search space of GEP consists of computer problems and mathematical models.\n",
    "```\n",
    "\n",
    "### Functions and terminals\n",
    "\n",
    "```\n",
    "Just following the terminology of GP, there are two kinds of primitives in GEP: function and terminal. A function is a primitive that can accepts one or more arguments and returns a result after evaluation, while a terminal represents a constant or a variable in a given program.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to GEP\n",
    "For example:\n",
    "\n",
    "Functions alphabet: [max, +, *]\n",
    "\n",
    "Terminals alphabet: (x, y, 3, 4)\n",
    "\n",
    "- gene <max,+,+,*,x,x,x,y,3,4,y>\n",
    "- gene = head <max,+,+,*> + tail <x,x,x,y,3,4,y>\n",
    "\n",
    "**Genotype**: \n",
    "\n",
    "max++*xxxy34y\n",
    "\n",
    "**Phenotype** (Expression Tree):\n",
    "```\n",
    "[max]\n",
    "    [+]\n",
    "        (x)\n",
    "        (x)\n",
    "    [+]\n",
    "        (x)\n",
    "    [*]\n",
    "        (y)\n",
    "        (3)\n",
    "```\n",
    "\n",
    "**ORF (K-expression)**\n",
    "\n",
    "[max, +, +, *, x, x, x, y, 3]\n",
    "\n",
    "```\n",
    "It is easy to notice that the last two elements in the gene donâ€™t appear in the expression tree. Although in GEP the start site is always the first position of a gene, the termination point does not always coincide with the last position of a gene. It is common for GEP genes to have non-coding regions downstream of the termination point. In such a sense, the decoding of genes (or chromosomes) into expression trees is similar to gene expression in nature. The coding region of a gene is called open reading frames (ORFs), which is also named K-expression in GEP.\n",
    "\n",
    "As stated previously, GEP chromosomes have fixed length and are composed of one or more genes of equal length. Therefore the length of a gene is also fixed. Thus, in GEP, what varies is not the length of genes (which is constant), but the length of the ORFs. Indeed, the length of an ORF may be equal to or less than the length of the gene. Due to the possible existence of non-coding regions in GEP genes, a gene of a fixed length can encode a variety of expression trees, i.e., computer programs or mathematical expressions. \n",
    "```\n",
    "\n",
    "- h - length of head\n",
    "- t - length of tail\n",
    "- n - maximum of arity of the function with the most arguments\n",
    "\n",
    "$t=h(n-1)+1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Examples of GEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install geppy\n",
    "#!pip3 install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Boolean function identification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a, b, c, d):\n",
    "    \"\"\" The true model, which only involves three inputs on purpose.\"\"\"\n",
    "    return (a and d) or not c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# generate the training set which contains all the 16 samples\n",
    "X = []\n",
    "Y = []\n",
    "for a, b, c, d in itertools.product([True, False], repeat=4):\n",
    "    X.append((a, b, c, d))\n",
    "    Y.append(f(a, b, c, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Creating the primitives set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geppy as gep\n",
    "import operator\n",
    "\n",
    "# terminals\n",
    "pset = gep.PrimitiveSet('Main', input_names=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# functions\n",
    "pset.add_function(operator.and_, 2)\n",
    "pset.add_function(operator.or_, 2)\n",
    "pset.add_function(operator.not_, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Create the individual and population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import creator, base, tools\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1,))  # to maximize the objective (fitness)\n",
    "creator.create(\"Individual\", gep.Chromosome, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 5   # head length\n",
    "n_genes = 2   # number of genes in a chromosome\n",
    "toolbox = gep.Toolbox()\n",
    "toolbox.register('gene_gen', gep.Gene, pset=pset, head_length=h)\n",
    "toolbox.register('individual', creator.Individual, gene_gen=toolbox.gene_gen, n_genes=n_genes, linker=operator.or_)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# compile utility: which translates an individual into an executable function (Lambda)\n",
    "toolbox.register('compile', gep.compile_, pset=pset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Define the fitness evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(individual):\n",
    "    \"\"\"Evalute the fitness of an individual\"\"\"\n",
    "    func = toolbox.compile(individual)  # a lambda function\n",
    "    n_correct = 0\n",
    "    for (a, b, c, d), y in zip(X, Y):\n",
    "        prediction = func(a, b, c, d)\n",
    "        if prediction == y:\n",
    "            n_correct += 1\n",
    "    return n_correct,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register('evaluate', evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Register genetic operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register('select', tools.selRoulette)\n",
    "\n",
    "## general mutations whose aliases start with 'mut'\n",
    "# We can specify the probability for an operator with the .pbs property\n",
    "toolbox.register('mut_uniform', gep.mutate_uniform, pset=pset, ind_pb=2 / (2 * h + 1))\n",
    "toolbox.pbs['mut_uniform'] = 0.1\n",
    "# Alternatively, assign the probability along with registration using the pb keyword argument.\n",
    "toolbox.register('mut_invert', gep.invert, pb=0.1)\n",
    "toolbox.register('mut_is_ts', gep.is_transpose, pb=0.1)\n",
    "toolbox.register('mut_ris_ts', gep.ris_transpose, pb=0.1)\n",
    "toolbox.register('mut_gene_ts', gep.gene_transpose, pb=0.1)\n",
    "\n",
    "## general crossover whose aliases start with 'cx'\n",
    "toolbox.register('cx_1p', gep.crossover_one_point, pb=0.1)\n",
    "toolbox.pbs['cx_1p'] = 0.4   # just show that the probability can be overwritten\n",
    "toolbox.register('cx_2p', gep.crossover_two_point, pb=0.2)\n",
    "toolbox.register('cx_gene', gep.crossover_gene, pb=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Statistics to be inspected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "\n",
    "stats = tools.Statistics(key=lambda ind: ind.fitness.values[0])\n",
    "stats.register(\"avg\", numpy.mean)\n",
    "stats.register(\"std\", numpy.std)\n",
    "stats.register(\"min\", numpy.min)\n",
    "stats.register(\"max\", numpy.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Launch evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section is just for reproduction purpose since evolutionary algorithms all involve randomness\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of population and number of generations\n",
    "n_pop = 50\n",
    "n_gen = 50\n",
    "\n",
    "pop = toolbox.population(n=n_pop)\n",
    "hof = tools.HallOfFame(1)   # only record the best individual ever found in all generations\n",
    "\n",
    "# start evolution\n",
    "pop, log = gep.gep_simple(pop, toolbox,\n",
    "                          n_generations=n_gen, n_elites=2,\n",
    "                          stats=stats, hall_of_fame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = hof[0]\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [optional] check the 11 primitives of each gene\n",
    "print('- Content of the two genes: ')\n",
    "for gene in best:\n",
    "    print(repr(gene))\n",
    "#[optional] we can also check the K-expression (only including primitives that are expressed) of a gene\n",
    "print('- K-expression of the two genes')\n",
    "for gene in best:\n",
    "    print(gene.kexpression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8 Post-processing: simplification and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symplified_best = gep.simplify(best)\n",
    "print('Symplified best individual: ')\n",
    "print(symplified_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_labels = {'and_': '&', 'or_': '|', 'not_': '~'}   # we want use symbol labels instead of words in the tree graph\n",
    "gep.export_expression_tree(best, rename_labels, 'data/bool_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the above image here for convenience\n",
    "from IPython.display import Image\n",
    "Image(filename='data/bool_tree.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GEP algorithm:\n",
    "- create trainig set (for evaluate metric calculating)\n",
    "- create primitives set (terminals and functions)\n",
    "- create individual (set the schema of individual)\n",
    "- crate population (set hyperparams)\n",
    "- set the evaluate function\n",
    "- set genetic operators\n",
    "- set the statistics (for verbose logging)\n",
    "- launch evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dummy regular expression optimization\n",
    "\n",
    "For test:\n",
    "\n",
    "There are functions:\n",
    "- alt (OR)\n",
    "- group (AND)\n",
    "\n",
    "There are terminals:\n",
    "- a\n",
    "- b\n",
    "- c\n",
    "\n",
    "Original regex:\n",
    "```\n",
    "a(b|c)(c|b)\n",
    "```\n",
    "\n",
    "Possible optimized regex:\n",
    "```\n",
    "abc|acb|acc|abb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMINALS = ['a', 'b', 'c']\n",
    "\n",
    "def alt(*args):\n",
    "    print(args)\n",
    "    \n",
    "def group(*args):\n",
    "    print(args)\n",
    "\n",
    "FUNCTIONS = {\n",
    "    alt: 2,\n",
    "    group: 3 + 1\n",
    "}\n",
    "TEST_STRINGS = [\n",
    "    # target 1\n",
    "    'abc',\n",
    "    'acb',\n",
    "    'acc',\n",
    "    'abb',\n",
    "    # target 0\n",
    "    'aaa',\n",
    "    'bbb',\n",
    "    'ccc',\n",
    "    'bca',\n",
    "]\n",
    "\n",
    "ORIGINAL_REGEX = 'a(b|c)(c|b)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "\n",
    "def f(string, regex):\n",
    "    re_comp = re.compile(regex)\n",
    "    try:\n",
    "        return re_comp.match(string).group()\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "def create_training_set(test_strings, original_regex):\n",
    "    Y = []\n",
    "    X = []\n",
    "    for string in test_strings:\n",
    "        X.append(string)\n",
    "        Y.append(f(string=string, regex=original_regex))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = create_training_set(\n",
    "    test_strings=TEST_STRINGS,\n",
    "    original_regex=ORIGINAL_REGEX\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Creating the primitives set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "import geppy as gep\n",
    "import operator\n",
    "\n",
    "def create_primitives_set(\n",
    "    terminals: List,\n",
    "    # key - function\n",
    "    # value - arity\n",
    "    functions: Dict\n",
    "\n",
    "):\n",
    "    # terminals\n",
    "    pset = gep.PrimitiveSet('Main', input_names=terminals)\n",
    "\n",
    "    # functions\n",
    "    for function in functions.keys():\n",
    "        pset.add_function(function, functions.get(function))\n",
    "    return pset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset = create_primitives_set(\n",
    "    terminals = TERMINALS,\n",
    "    functions = FUNCTIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# terminals\n",
    "pset._terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "pset._functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Create the individual and population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import creator, base, tools\n",
    "\n",
    "def create_individual():\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1,))   # to minimize the objective (fitness)\n",
    "    creator.create(\"Individual\", gep.Chromosome, fitness=creator.FitnessMin)\n",
    "    return creator\n",
    "\n",
    "def create_popiulation(\n",
    "    pset,\n",
    "    head_length: int = 5,\n",
    "    genes_number_in_chromosome: int = 2,\n",
    "):\n",
    "\n",
    "    h = head_length   # head length\n",
    "    n_genes = genes_number_in_chromosome   # number of genes in a chromosome\n",
    "    toolbox = gep.Toolbox()\n",
    "    toolbox.register('gene_gen', gep.Gene, pset=pset, head_length=h)\n",
    "    toolbox.register(\n",
    "        'individual', \n",
    "        creator.Individual, \n",
    "        gene_gen=toolbox.gene_gen, \n",
    "        n_genes=n_genes,\n",
    "        linker=group\n",
    "    )\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    # compile utility: which translates an individual into an executable function (Lambda)\n",
    "    toolbox.register('compile', gep.compile_, pset=pset)\n",
    "    return toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set individual\n",
    "\n",
    "creator = create_individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set population\n",
    "toolbox = create_popiulation(\n",
    "    pset=pset, \n",
    "    head_length=5,\n",
    "    genes_number_in_chromosome=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toolbox.individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Define the fitness evaluationfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "N_ITER = 100\n",
    "\n",
    "def get_match_accuracy(regex, phrase, result):\n",
    "    try:\n",
    "        reg_result = regex.match(phrase).group()\n",
    "        if reg_result == result:\n",
    "            return 1\n",
    "        return 0\n",
    "    except AttributeError:\n",
    "        return 0\n",
    "        \n",
    "def get_performance_metric(regex, n_iter, test_strings):\n",
    "    t0 = time.time() * 1000\n",
    "    for _ in range(n_iter):\n",
    "        for test_string in test_strings:\n",
    "            _ = regex.match(test_string)\n",
    "    return ((time.time() * 1000 - t0) / n_iter) / len(test_strings)\n",
    "\n",
    "\n",
    "def dummy_lexical_analyzer(string):\n",
    "    sep_symbols = ['(', ')', ',']\n",
    "    tokens = []\n",
    "    _current_token = ''\n",
    "    for symbol in string:\n",
    "        if symbol in sep_symbols:\n",
    "            if _current_token != '':\n",
    "                tokens.append(_current_token)\n",
    "            tokens.append(symbol)\n",
    "            _current_token = ''\n",
    "        else:\n",
    "            _current_token += symbol\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def dummy_generator(tokens, current_state=None):\n",
    "    result = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in TERMINALS:\n",
    "            result.append(token)\n",
    "        elif token == ',' and current_state == 'alt':\n",
    "            result.append('|')\n",
    "        elif token in ['(', ')'] and current_state in ['group', 'alt']:\n",
    "            result.append(token)\n",
    "        elif token == 'group':\n",
    "            current_state = 'group'\n",
    "        elif token == 'alt':\n",
    "            current_state = 'alt'\n",
    "    return result\n",
    "\n",
    "def regex_compile(individual):\n",
    "    individual = re.sub(r'\\s', '', str(individual))\n",
    "    tokens = dummy_lexical_analyzer(individual)\n",
    "    regex = ''.join(dummy_generator(tokens))\n",
    "    return re.compile(regex)\n",
    "\n",
    "def evaluate(individual):\n",
    "    global X, Y\n",
    "    try:\n",
    "        regex = regex_compile(individual)\n",
    "    except:\n",
    "        return 1\n",
    "    \n",
    "    # count accuracy metric\n",
    "    accuracy = []\n",
    "    for x, y in zip(X, Y):\n",
    "        accuracy.append(\n",
    "            get_match_accuracy(\n",
    "                regex=regex, \n",
    "                phrase=x, \n",
    "                result=y\n",
    "            )\n",
    "        )\n",
    "    coeff = (2. - sum(accuracy)/len(accuracy))\n",
    "\n",
    "    # count performance metric\n",
    "    res_metric = coeff * float(\n",
    "        get_performance_metric(\n",
    "            regex=regex,\n",
    "            n_iter=N_ITER,\n",
    "            test_strings=X\n",
    "    ))\n",
    "    \n",
    "    return res_metric,\n",
    "\n",
    "def set_evalute_function(\n",
    "    toolbox,\n",
    "    evaluate_function\n",
    "):\n",
    "    toolbox.register('evaluate', evaluate_function)\n",
    "    return toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = set_evalute_function(toolbox, evaluate_function=evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Register genetic operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genetic_operators(\n",
    "    toolbox,\n",
    "    pset,\n",
    "    head_length: int = 5\n",
    "):\n",
    "    toolbox.register('select', tools.selRoulette)\n",
    "    ## general mutations whose aliases start with 'mut'\n",
    "    # We can specify the probability for an operator with the .pbs property\n",
    "    toolbox.register('mut_uniform', gep.mutate_uniform, pset=pset, ind_pb=2 / (2 * head_length + 1))\n",
    "    toolbox.pbs['mut_uniform'] = 0.1\n",
    "    # Alternatively, assign the probability along with registration using the pb keyword argument.\n",
    "    toolbox.register('mut_invert', gep.invert, pb=0.1)\n",
    "    toolbox.register('mut_is_ts', gep.is_transpose, pb=0.1)\n",
    "    toolbox.register('mut_ris_ts', gep.ris_transpose, pb=0.1)\n",
    "    toolbox.register('mut_gene_ts', gep.gene_transpose, pb=0.1)\n",
    "\n",
    "    ## general crossover whose aliases start with 'cx'\n",
    "    toolbox.register('cx_1p', gep.crossover_one_point, pb=0.1)\n",
    "    toolbox.pbs['cx_1p'] = 0.4   # just show that the probability can be overwritten\n",
    "    toolbox.register('cx_2p', gep.crossover_two_point, pb=0.2)\n",
    "    toolbox.register('cx_gene', gep.crossover_gene, pb=0.1)\n",
    "    return toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = set_genetic_operators(toolbox, pset=pset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Statistics to be inspected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def set_statistic(\n",
    "    statistics_dict: Dict = {\n",
    "        \"avg\": np.mean,\n",
    "        \"std\": np.std,\n",
    "        \"min\": np.min,\n",
    "        \"max\": np.max\n",
    "    }\n",
    "):\n",
    "\n",
    "    stats = tools.Statistics(key=lambda ind: ind.fitness.values[0])\n",
    "    for statistic_name in statistics_dict.keys():\n",
    "        stats.register(statistic_name, statistics_dict[statistic_name])\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = set_statistic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 Launch evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def launch_evolution(\n",
    "    toolbox,\n",
    "    stats,\n",
    "    seed: int = 11,\n",
    "):\n",
    "    # this section is just for reproduction purpose since evolutionary algorithms all involve randomness\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # size of population and number of generations\n",
    "    n_pop = 50\n",
    "    n_gen = 50\n",
    "\n",
    "    pop = toolbox.population(n=n_pop)\n",
    "    hof = tools.HallOfFame(1)   # only record the best individual ever found in all generations\n",
    "\n",
    "    # start evolution\n",
    "    pop, log = gep.gep_simple(pop, toolbox,\n",
    "                              n_generations=n_gen, n_elites=2,\n",
    "                              stats=stats, hall_of_fame=hof, verbose=True)\n",
    "    \n",
    "    best = hof[0]\n",
    "    print(best)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best = launch_evolution(\n",
    "    toolbox=toolbox,\n",
    "    stats=stats,\n",
    "    seed=456,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 Post-processing: simplification and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_individuals(best):\n",
    "    print('- Content of the two genes: ')\n",
    "    for gene in best:\n",
    "        print(repr(gene))\n",
    "    print('- K-expression of the two genes')\n",
    "    for gene in best:\n",
    "        print(gene.kexpression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "see_individuals(best=best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_labels = {'group': 'group', 'alt': 'alt'}\n",
    "gep.export_expression_tree(best, rename_labels, 'data/dummy_regexp_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='data/dummy_regexp_tree.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Regular expression optimization\n",
    "\n",
    "There are functions:\n",
    "- alt\n",
    "- group\n",
    "- escape\n",
    "- repeat (only for params from memory)\n",
    "- range (only for params from memory)\n",
    "\n",
    "There are terminals:\n",
    "- all unicode letters\n",
    "- any\n",
    "\n",
    "Original regex:\n",
    "```\n",
    "ab?c.|[0-9]\\[\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1  Synthetic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare terminals (all unicode letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "from geppy.core.symbol import _is_nonkeyword_identifier\n",
    "\n",
    "def get_all_unicode_letters(start_code, stop_code):\n",
    "    start_idx, stop_idx = [int(code, 16) for code in (start_code, stop_code)]\n",
    "    characters = []\n",
    "    for unicode_idx in range(start_idx, stop_idx + 1):\n",
    "        characters.append(chr(unicode_idx))\n",
    "    return characters\n",
    "\n",
    "TERMINALS = []\n",
    "\n",
    "# Latin upper\n",
    "TERMINALS += get_all_unicode_letters('0041', '005A')\n",
    "\n",
    "# Latin lower\n",
    "TERMINALS += get_all_unicode_letters('0061', '007A')\n",
    "\n",
    "# digits\n",
    "TERMINALS += get_all_unicode_letters('0030', '0039')\n",
    "\n",
    "# check ability to get __name__\n",
    "correct_terminals = []\n",
    "\n",
    "for x in TERMINALS:\n",
    "    try:\n",
    "        assert _is_nonkeyword_identifier(x)\n",
    "        correct_terminals.append(x)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "TERMINALS = correct_terminals\n",
    "\n",
    "# range group and escape in this work will be terminals\n",
    "TERMINALS += ['range', 'any', 'escape']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt(*args):\n",
    "    return args\n",
    "    \n",
    "def group(*args):\n",
    "    return args\n",
    "\n",
    "def repeat(*args):\n",
    "    return args\n",
    "\n",
    "FUNCTIONS = {\n",
    "    alt: 2,\n",
    "    group: 10,\n",
    "    repeat: 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare test strings and define original regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exrex\n",
    "\n",
    "ORIGINAL_REGEX = 'ab?c.|[0-9]\\['\n",
    "\n",
    "PARAMS = {\n",
    "    'range': ['0-9'],\n",
    "    'repeat': ['0,1']\n",
    "}\n",
    "\n",
    "N_FUZZY_STRINGS = 5\n",
    "\n",
    "TEST_STRINGS = list(exrex.generate(ORIGINAL_REGEX, limit=N_FUZZY_STRINGS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "\n",
    "def f(string, regex):\n",
    "    re_comp = re.compile(regex)\n",
    "    try:\n",
    "        return re_comp.match(string).group()\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "def create_training_set(test_strings, original_regex):\n",
    "    Y = []\n",
    "    X = []\n",
    "    for string in test_strings:\n",
    "        X.append(string)\n",
    "        Y.append(f(string=string, regex=original_regex))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = create_training_set(\n",
    "    test_strings=TEST_STRINGS,\n",
    "    original_regex=ORIGINAL_REGEX\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Creating the primitives set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "import geppy as gep\n",
    "import operator\n",
    "\n",
    "def create_primitives_set(\n",
    "    terminals: List,\n",
    "    # key - function\n",
    "    # value - arity\n",
    "    functions: Dict\n",
    "\n",
    "):\n",
    "    # terminals\n",
    "    pset = gep.PrimitiveSet('Main', input_names=terminals)\n",
    "\n",
    "    # functions\n",
    "    for function in functions.keys():\n",
    "        pset.add_function(function, functions.get(function))\n",
    "    return pset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset = create_primitives_set(\n",
    "    terminals = TERMINALS,\n",
    "    functions = FUNCTIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Create the individual and population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import creator, base, tools\n",
    "\n",
    "def create_individual():\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1,))   # to minimize the objective (fitness)\n",
    "    creator.create(\"Individual\", gep.Chromosome, fitness=creator.FitnessMin)\n",
    "    return creator\n",
    "\n",
    "def create_popiulation(\n",
    "    pset,\n",
    "    head_length: int = 5,\n",
    "    genes_number_in_chromosome: int = 2,\n",
    "):\n",
    "\n",
    "    h = head_length   # head length\n",
    "    n_genes = genes_number_in_chromosome   # number of genes in a chromosome\n",
    "    toolbox = gep.Toolbox()\n",
    "    toolbox.register('gene_gen', gep.Gene, pset=pset, head_length=h)\n",
    "    toolbox.register(\n",
    "        'individual', \n",
    "        creator.Individual, \n",
    "        gene_gen=toolbox.gene_gen, \n",
    "        n_genes=n_genes,\n",
    "        linker=group\n",
    "    )\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    # compile utility: which translates an individual into an executable function (Lambda)\n",
    "    toolbox.register('compile', gep.compile_, pset=pset)\n",
    "    return toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set individual\n",
    "\n",
    "creator = create_individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set population\n",
    "toolbox = create_popiulation(\n",
    "    pset=pset, \n",
    "    head_length=5,\n",
    "    genes_number_in_chromosome=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Define the fitness evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "N_ITER = 100\n",
    "\n",
    "def get_match_accuracy(regex, phrase, result):\n",
    "    try:\n",
    "        reg_result = regex.match(phrase).group()\n",
    "        if reg_result == result:\n",
    "            return 1\n",
    "        return 0\n",
    "    except AttributeError:\n",
    "        return 0\n",
    "        \n",
    "def get_performance_metric(regex, n_iter, test_strings):\n",
    "    t0 = time.time() * 1000\n",
    "    for _ in range(n_iter):\n",
    "        for test_string in test_strings:\n",
    "            _ = regex.match(test_string)\n",
    "    return ((time.time() * 1000 - t0) / n_iter) / len(test_strings)\n",
    "\n",
    "\n",
    "def lexical_analyzer(string):\n",
    "    sep_symbols = ['(', ')', ',']\n",
    "    tokens = []\n",
    "    _current_token = ''\n",
    "    for symbol in string:\n",
    "        if symbol in sep_symbols:\n",
    "            if _current_token != '':\n",
    "                tokens.append(_current_token)\n",
    "            tokens.append(symbol)\n",
    "            _current_token = ''\n",
    "        else:\n",
    "            _current_token += symbol\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def generator(tokens, current_state=None):\n",
    "    result = []\n",
    "    repeat = False\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in TERMINALS:\n",
    "            # work with special terminals\n",
    "            if token == 'escape':\n",
    "                result.append('\\\\')\n",
    "            elif token == 'any':\n",
    "                result.append('.')\n",
    "            elif token == 'range':\n",
    "                result.append(f'[{random.choice(PARAMS[\"range\"])}]')\n",
    "            else:\n",
    "                result.append(token)\n",
    "        # add arguments\n",
    "        elif token == ',' and current_state == 'alt':\n",
    "            result.append('|')\n",
    "        elif token == ')' and repeat is True and current_state is None:\n",
    "            result.append(f'{\"{\"}{random.choice(PARAMS[\"repeat\"])}{\"}\"}')\n",
    "            repeat = False\n",
    "        elif token == '(' and current_state in ['group', 'alt']:\n",
    "            result.append(token)\n",
    "        elif token == ')':\n",
    "            current_state = None\n",
    "            result.append(')')\n",
    "        # check functions\n",
    "        elif token == 'group':\n",
    "            current_state = 'group'\n",
    "        elif token == 'repeat':\n",
    "            repeat = True\n",
    "        elif token == 'alt':\n",
    "            current_state = 'alt'\n",
    "    return result\n",
    "\n",
    "def regex_compile(individual):\n",
    "    individual = re.sub(r'\\s', '', str(individual))\n",
    "    tokens = lexical_analyzer(individual)\n",
    "    regex = ''.join(generator(tokens)) + ')'\n",
    "    try:\n",
    "        return re.compile(regex), None\n",
    "    except Exception as e:\n",
    "        return None, f'error: {e}, string: {regex}'\n",
    "\n",
    "def evaluate(individual):\n",
    "    global X, Y\n",
    "    regex = regex_compile(individual)[0]\n",
    "    \n",
    "    if not regex:\n",
    "        return 1_000,\n",
    "    \n",
    "    # count accuracy metric\n",
    "    accuracy = []\n",
    "    for x, y in zip(X, Y):\n",
    "        accuracy.append(\n",
    "            get_match_accuracy(\n",
    "                regex=regex, \n",
    "                phrase=x, \n",
    "                result=y\n",
    "            )\n",
    "        )\n",
    "    accuracy = sum(accuracy)/len(accuracy)\n",
    "\n",
    "    try:\n",
    "        res_metric = float(\n",
    "            get_performance_metric(\n",
    "                regex=regex,\n",
    "                n_iter=N_ITER,\n",
    "                test_strings=X\n",
    "        )) / accuracy\n",
    "    except ZeroDivisionError:\n",
    "        res_metric = 1_000\n",
    "\n",
    "    return res_metric,\n",
    "\n",
    "def set_evalute_function(\n",
    "    toolbox,\n",
    "    evaluate_function\n",
    "):\n",
    "    toolbox.register('evaluate', evaluate_function)\n",
    "    return toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = set_evalute_function(toolbox, evaluate_function=evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Register genetic operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genetic_operators(\n",
    "    toolbox,\n",
    "    pset,\n",
    "    head_length: int = 5\n",
    "):\n",
    "    toolbox.register('select', tools.selRoulette)\n",
    "    ## general mutations whose aliases start with 'mut'\n",
    "    # We can specify the probability for an operator with the .pbs property\n",
    "    toolbox.register('mut_uniform', gep.mutate_uniform, pset=pset, ind_pb=2 / (2 * head_length + 1))\n",
    "    toolbox.pbs['mut_uniform'] = 0.3\n",
    "    # Alternatively, assign the probability along with registration using the pb keyword argument.\n",
    "    toolbox.register('mut_invert', gep.invert, pb=0.1)\n",
    "    toolbox.register('mut_is_ts', gep.is_transpose, pb=0.1)\n",
    "    toolbox.register('mut_ris_ts', gep.ris_transpose, pb=0.1)\n",
    "    toolbox.register('mut_gene_ts', gep.gene_transpose, pb=0.4)\n",
    "\n",
    "    ## general crossover whose aliases start with 'cx'\n",
    "    toolbox.register('cx_1p', gep.crossover_one_point, pb=0.1)\n",
    "    toolbox.pbs['cx_1p'] = 0.4   # just show that the probability can be overwritten\n",
    "    toolbox.register('cx_2p', gep.crossover_two_point, pb=0.2)\n",
    "    toolbox.register('cx_gene', gep.crossover_gene, pb=0.1)\n",
    "    return toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = set_genetic_operators(toolbox, pset=pset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Statistics to be inspected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def set_statistic(\n",
    "    statistics_dict: Dict = {\n",
    "        \"avg\": np.mean,\n",
    "        \"std\": np.std,\n",
    "        \"min\": np.min,\n",
    "        \"max\": np.max\n",
    "    }\n",
    "):\n",
    "\n",
    "    stats = tools.Statistics(key=lambda ind: ind.fitness.values[0])\n",
    "    for statistic_name in statistics_dict.keys():\n",
    "        stats.register(statistic_name, statistics_dict[statistic_name])\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = set_statistic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Launch evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def launch_evolution(\n",
    "    toolbox,\n",
    "    stats,\n",
    "    seed: int = 11,\n",
    "):\n",
    "    # this section is just for reproduction purpose since evolutionary algorithms all involve randomness\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # size of population and number of generations\n",
    "    n_pop = 500\n",
    "    n_gen = 100\n",
    "\n",
    "    pop = toolbox.population(n=n_pop)\n",
    "    hof = tools.HallOfFame(1)   # only record the best individual ever found in all generations\n",
    "\n",
    "    # start evolution\n",
    "    pop, log = gep.gep_simple(pop, toolbox,\n",
    "                              n_generations=n_gen, n_elites=2,\n",
    "                              stats=stats, hall_of_fame=hof, verbose=True)\n",
    "    \n",
    "    best = hof[0]\n",
    "    print(best)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = launch_evolution(\n",
    "    toolbox=toolbox,\n",
    "    stats=stats,\n",
    "    seed=156,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8 Post-processing: simplification and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_individuals(best):\n",
    "    print('- Content of the two genes: ')\n",
    "    for gene in best:\n",
    "        print(repr(gene))\n",
    "    print('- K-expression of the two genes')\n",
    "    for gene in best:\n",
    "        print(gene.kexpression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "see_individuals(best=best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_labels = {'group': 'group', 'alt': 'alt', 'repeat': 'repeat', 'escape': 'escape', '_range': 'range'}\n",
    "gep.export_expression_tree(best, rename_labels, 'data/regexp_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='data/regexp_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_compile(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
